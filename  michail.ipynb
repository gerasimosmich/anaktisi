{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2101c017-e774-40f9-952a-ab32a2fc607b",
   "metadata": {},
   "source": [
    "# Επεξεργασία και Αναζήτηση Κειμένων BBC\n",
    "### Ονοματεπώνυμο: Γεράσιμος Μιχαήλ\n",
    "### Ημερομηνία: 09/01/2025\n",
    "### Σύνδεσμος: [https://github.com/gerasimosmich/anaktisi](https://github.com/gerasimosmich/anaktisi)\n",
    "\n",
    "---\n",
    "\n",
    "## Περιγραφή\n",
    "Αυτό το Notebook περιλαμβάνει:\n",
    "- Προεπεξεργασία δεδομένων από το dataset BBC.\n",
    "- Δημιουργία ανεστραμμένου ευρετηρίου.\n",
    "- Υλοποίηση Boolean queries.\n",
    "- Υπολογισμό και κατάταξη εγγράφων με TF-IDF.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e735413-7e20-472f-8153-86215c5e11e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\Makis\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import json\n",
    "import string\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from collections import defaultdict\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# ## Εγκατάσταση και φόρτωση δεδομένων του NLTK\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132fa58f-9346-4508-a571-5f044f953eae",
   "metadata": {},
   "source": [
    "# ## Ερώτημα 1 και 2: Φόρτωση και Επεξεργασία Δεδομένων\n",
    "# ### Φόρτωση δεδομένων από αρχεία\n",
    "# Path για τα δεδομένα"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b480119b-3595-428e-b349-3daf20051e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The preprocessed dataset has been saved at ./bbc_preprocessed_dataset.json\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './archive/bbc'\n",
    "output_json_path = './bbc_dataset.json'\n",
    "\n",
    "# Ανάγνωση JSON ή δημιουργία αν δεν υπάρχουν\n",
    "if os.path.exists(output_json_path):\n",
    "    with open(output_json_path, 'r', encoding='utf-8') as json_file:\n",
    "        documents = json.load(json_file)\n",
    "else:\n",
    "    documents = []\n",
    "    # Επεξεργασία TXT αρχείων και μετατροπή σε JSON\n",
    "    for category in os.listdir(dataset_path):\n",
    "        category_path = os.path.join(dataset_path, category)\n",
    "        if os.path.isdir(category_path):  # Ελέγχει αν είναι φάκελος\n",
    "            for file_name in os.listdir(category_path):\n",
    "                file_path = os.path.join(category_path, file_name)\n",
    "                if os.path.isfile(file_path):  # Ελέγχει αν είναι αρχείο\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        lines = file.readlines()\n",
    "                        # Πρώτη γραμμή ως τίτλος, υπόλοιπο ως περιεχόμενο\n",
    "                        title = lines[0].strip() if lines else \"No Title\"\n",
    "                        content = \" \".join(line.strip() for line in lines[1:])\n",
    "                        documents.append({\n",
    "                            \"category\": category,\n",
    "                            \"title\": title,\n",
    "                            \"content\": content\n",
    "                        })\n",
    "    # Αποθήκευση στο JSON\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(documents, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "# ### Προεπεξεργασία δεδομένων\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Καθαρισμός ειδικών χαρακτήρων\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text, language='english')\n",
    "    \n",
    "    # Αφαίρεση stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Stemming και Lemmatization\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    return {\n",
    "        \"original\": tokens,\n",
    "        \"stemmed\": stemmed,\n",
    "        \"lemmatized\": lemmatized\n",
    "    }\n",
    "\n",
    "# Εφαρμογή προεπεξεργασίας σε κάθε έγγραφο\n",
    "for document in documents:\n",
    "    processed_content = preprocess_text(document['content'])\n",
    "    document['processed_content'] = processed_content\n",
    "\n",
    "# ### Αποθήκευση προεπεξεργασμένων δεδομένων\n",
    "preprocessed_json_path = './bbc_preprocessed_dataset.json'\n",
    "with open(preprocessed_json_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(documents, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"The preprocessed dataset has been saved at {}\".format(preprocessed_json_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107ebc8f-85bd-4144-9d2b-3e17629ebc26",
   "metadata": {},
   "source": [
    "# ## Ερώτημα 3: Δημιουργία Ανεστραμμένου Ευρετηρίου\n",
    "# ### Κατασκευή του ανεστραμμένου ευρετηρίου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb08fadb-67f7-479f-b542-d6df2ab92bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Το ανεστραμμένο ευρετήριο αποθηκεύτηκε στο ./inverted_index.json\n"
     ]
    }
   ],
   "source": [
    "inverted_index_output_path = './inverted_index.json'\n",
    "\n",
    "# Φόρτωση επεξεργασμένων δεδομένων\n",
    "with open(preprocessed_json_path, 'r', encoding='utf-8') as json_file:\n",
    "    documents = json.load(json_file)\n",
    "\n",
    "# Δημιουργία ανεστραμμένου ευρετηρίου\n",
    "inverted_index = defaultdict(list)\n",
    "\n",
    "# Κατασκευή ευρετηρίου\n",
    "for doc_id, document in enumerate(documents):\n",
    "    words = document['processed_content']['lemmatized']  # Χρησιμοποιούμε τη lemmatized μορφή\n",
    "    for word in set(words):  # Χρησιμοποιούμε set για να αποφύγουμε διπλοεγγραφές λέξεων\n",
    "        inverted_index[word].append(doc_id)\n",
    "\n",
    "# Αποθήκευση του ευρετηρίου σε αρχείο JSON\n",
    "with open(inverted_index_output_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(inverted_index, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(\"Το ανεστραμμένο ευρετήριο αποθηκεύτηκε στο {}\".format(inverted_index_output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca29fd4-564a-457f-821a-7536f42a759d",
   "metadata": {},
   "source": [
    "# ## Ερώτημα 4: Αναζήτηση με Boolean Queries\n",
    "# ### Υλοποίηση Boolean Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26a9a67d-cbe9-4c65-9b3a-a6f2b5ea457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Δώσε το ερώτημα σου (Boolean ή απλές λέξεις-κλειδιά):  Alexander\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Βρέθηκαν 1 σχετικά έγγραφα:\n",
      "- Ad sales boost Time Warner profit (Category: business)\n"
     ]
    }
   ],
   "source": [
    "def process_query(query, inverted_index):\n",
    "    \"\"\"\n",
    "    Επεξεργασία του ερωτήματος και επιστροφή σχετικών εγγράφων.\n",
    "    Υποστηρίζει απλές λέξεις-κλειδιά και Boolean queries.\n",
    "    \"\"\"\n",
    "    # Χωρισμός ερωτήματος σε λέξεις\n",
    "    terms = query.lower().split()\n",
    "    \n",
    "    # Ανάλυση Boolean Queries\n",
    "    if 'and' in terms or 'or' in terms or 'not' in terms:\n",
    "        result_set = set()\n",
    "        current_set = set()\n",
    "        operator = None\n",
    "        \n",
    "        for term in terms:\n",
    "            if term in ['and', 'or', 'not']:\n",
    "                operator = term\n",
    "            else:\n",
    "                # Λήψη των εγγράφων από το ευρετήριο\n",
    "                term_docs = set(inverted_index.get(term, []))\n",
    "                \n",
    "                if operator == 'not':\n",
    "                    term_docs = set(range(len(documents))) - term_docs\n",
    "                \n",
    "                if not result_set:\n",
    "                    result_set = term_docs\n",
    "                else:\n",
    "                    if operator == 'and':\n",
    "                        result_set &= term_docs\n",
    "                    elif operator == 'or':\n",
    "                        result_set |= term_docs\n",
    "        return list(result_set)\n",
    "    \n",
    "    # Απλή αναζήτηση (λέξεις-κλειδιά)\n",
    "    else:\n",
    "        result_docs = set()\n",
    "        for term in terms:\n",
    "            result_docs.update(inverted_index.get(term, []))\n",
    "        return list(result_docs)\n",
    "\n",
    "# ### Εκτέλεση Boolean Queries\n",
    "with open('./inverted_index.json', 'r', encoding='utf-8') as json_file:\n",
    "    inverted_index = json.load(json_file)\n",
    "\n",
    "query = input(\"Δώσε το ερώτημα σου (Boolean ή απλές λέξεις-κλειδιά): \")\n",
    "matching_docs = process_query(query, inverted_index)\n",
    "\n",
    "# ### Εμφάνιση αποτελεσμάτων\n",
    "if matching_docs:\n",
    "    print(\"Βρέθηκαν {} σχετικά έγγραφα:\". format(len(matching_docs)))\n",
    "    for doc_id in matching_docs:\n",
    "        print(\"- {} (Category: {})\".format(documents[doc_id]['title'], documents[doc_id]['category']))\n",
    "\n",
    "else:\n",
    "    print(\"Δεν βρέθηκαν σχετικά έγγραφα.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e7ca5e-8d2c-4237-b828-6d0866a1a2c4",
   "metadata": {},
   "source": [
    "# ## Ερώτημα 5: Κατάταξη με TF-IDF\n",
    "# ### Υλοποίηση TF-IDF\n",
    "# Υπολογισμός TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee58ac5-219a-449f-83af-ea9b45a5f3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Δώσε το ερώτημά σου (λέξεις-κλειδιά):  Andersen AND Prince\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Βρέθηκαν 1 σχετικά έγγραφα με κατάταξη:\n",
      "1. Jarre joins fairytale celebration (Category: entertainment, Score: 0.0863)\n"
     ]
    }
   ],
   "source": [
    "def compute_tf(term, document):\n",
    "    tokens = document['processed_content']['lemmatized']\n",
    "    term_count = tokens.count(term)\n",
    "    return term_count / len(tokens) if tokens else 0\n",
    "\n",
    "# Υπολογισμός IDF\n",
    "def compute_idf(term, inverted_index, total_documents):\n",
    "    doc_count = len(inverted_index.get(term, []))\n",
    "    return math.log((1 + total_documents) / (1 + doc_count))\n",
    "\n",
    "# Υπολογισμός TF-IDF για ένα ερώτημα\n",
    "def rank_documents(query, documents, inverted_index):\n",
    "    total_documents = len(documents)\n",
    "    query_terms = query.lower().split()\n",
    "    scores = defaultdict(float)\n",
    "\n",
    "    # Υπολογισμός IDF για κάθε όρο του ερωτήματος\n",
    "    idf_values = {term: compute_idf(term, inverted_index, total_documents) for term in query_terms}\n",
    "\n",
    "    # Υπολογισμός TF-IDF για κάθε έγγραφο\n",
    "    for term in query_terms:\n",
    "        for doc_id in inverted_index.get(term, []):\n",
    "            tf = compute_tf(term, documents[doc_id])\n",
    "            scores[doc_id] += tf * idf_values[term]\n",
    "\n",
    "    # Ταξινόμηση εγγράφων με βάση το σκορ TF-IDF\n",
    "    ranked_documents = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    return ranked_documents\n",
    "\n",
    "# ### Εκτέλεση TF-IDF Κατάταξης\n",
    "query = input(\"Δώσε το ερώτημά σου (λέξεις-κλειδιά): \")\n",
    "\n",
    "ranked_docs = rank_documents(query, documents, inverted_index)\n",
    "\n",
    "# ### Εμφάνιση αποτελεσμάτων\n",
    "if ranked_docs:\n",
    "    print(\"Βρέθηκαν {} σχετικά έγγραφα με κατάταξη:\".format(len(ranked_docs)))\n",
    "    for rank, (doc_id, score) in enumerate(ranked_docs, start=1):\n",
    "        print(\"{}. {} (Category: {}, Score: {:.4f})\".format(rank, documents[doc_id]['title'], documents[doc_id]['category'], score))\n",
    "else:\n",
    "    print(\"Δεν βρέθηκαν σχετικά έγγραφα.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
